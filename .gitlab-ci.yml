image:
  name: docker/compose:1.24.1
  entrypoint: ["/bin/sh","-l","-c"]

services:
  - docker:dind

stages:
  - test
  - deploy

linting:
  stage: test
  image: python:3.9.13
  script:
    - pip install --upgrade black==22.3.0
    # make sure that the *same* version is used in Pipfiles to avoid incompatibilities:
    - grep 'black = "==22.3.0"' rest/Pipfile
    # check the files for correct formatting:
    - black -l 120 --check . || exit 1

integration tests:
  stage: test
  script:
    - '[ "`df -m / | tail -n -1 | awk ''{ print $4}''`" -ge "10" ] || (echo "NO DISK SPACE LEFT" && exit 1)'
    - docker-compose -f docker-compose.yml -f docker-compose.pytest.yml build
    - docker-compose -f docker-compose.yml -f docker-compose.pytest.yml up --exit-code-from pytest
  after_script:
    - docker-compose -f docker-compose.yml -f docker-compose.pytest.yml down -v
  allow_failure: true

## GITHUB:
publish_github:
  stage: deploy
  when: manual
  only:
    - master
  before_script:
    - apk add --no-cache git openssh-client
  script:
    # prepare SSH credentials for cloning from GitHub:
    - mkdir -m 700 ~/.ssh
    - echo ${GITHUB_SSH_PRIVATE_KEY_BASE64} | base64 -d > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - echo ${GITHUB_SSH_KNOWN_HOST} > ~/.ssh/known_hosts
    # remove remote for github repo if it exists:
    - if git remote | grep github > /dev/null; then git remote rm github; fi
    # add remote for github repo:
    - git remote add github git@github.com:Open-EO/openeo-sentinelhub-python-driver.git
    - git config --global user.email "info@sinergise.com"
    - git config --global user.name "sentinel-hub"
    - git push github master
    - git push --tags github master
  after_script:
    # clean the git remotes even if job fails
    # remove remote for github if it exists
    - if git remote | grep github > /dev/null; then git remote rm github; fi


deploy-testing-rest-lambda:
  stage: deploy
  when: manual
  only:
    variables:
      - $CI_COMMIT_TAG =~ /^v[0-9]+[.][0-9]+[.][0-9]+[-]rc.[0-9]+$/
  image: python:3.9.13
  before_script:
    # configure aws access credentials:
    - mkdir -p ~/.aws
    - echo -e "[default]\nregion=eu-central-1" > ~/.aws/config
    - echo -e "[default]\naws_access_key_id=$TESTINGZAPPA_AWS_ACCESS_KEY_ID\naws_secret_access_key=$TESTINGZAPPA_AWS_SECRET_ACCESS_KEY" > ~/.aws/credentials
    - pip install pipenv==2021.5.29
  script:
    - chmod +x download-process-definitions.sh
    - ./download-process-definitions.sh
    - cd rest/
    - pipenv install --dev
    # create zappa_settings.json on-the-fly:
    - cp zappa_settings.json.template zappa_settings.json
    - sed -i "s/@@AWS_ACCESS_KEY_ID@@/$TESTINGDATA_AWS_ACCESS_KEY_ID/g" zappa_settings.json
    - sed -i "s#@@AWS_SECRET_ACCESS_KEY@@#$TESTINGDATA_AWS_SECRET_ACCESS_KEY#g" zappa_settings.json
    - sed -i "s/@@TESTING_SH_CLIENT_ID@@/$TESTING_SH_CLIENT_ID/g" zappa_settings.json
    - sed -i "s/@@TESTING_SH_CLIENT_SECRET@@/$TESTING_SH_CLIENT_SECRET/g" zappa_settings.json
    - sed -i "s/@@BACKEND_VERSION@@/$CI_COMMIT_TAG/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_NAME_MAIN@@/$RESULTS_S3_BUCKET_NAME_MAIN/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_NAME_CREODIAS@@/$RESULTS_S3_BUCKET_NAME_CREODIAS/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_NAME_USWEST@@/$RESULTS_S3_BUCKET_NAME_USWEST/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_ACCESS_KEY_ID_MAIN@@/$RESULTS_S3_BUCKET_ACCESS_KEY_ID_MAIN/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_ACCESS_KEY_ID_CREODIAS@@/$RESULTS_S3_BUCKET_ACCESS_KEY_ID_CREODIAS/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_ACCESS_KEY_ID_USWEST@@/$RESULTS_S3_BUCKET_ACCESS_KEY_ID_USWEST/g" zappa_settings.json
    - sed -i "s#@@RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_MAIN@@#$RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_MAIN#g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_CREODIAS@@/$RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_CREODIAS/g" zappa_settings.json
    - sed -i "s#@@RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_USWEST@@#$RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_USWEST#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_BASE_URL_TESTING@@#$USAGE_REPORTING_BASE_URL_TESTING#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_AUTH_URL_TESTING@@#$USAGE_REPORTING_AUTH_URL_TESTING#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_AUTH_CLIENT_ID_TESTING@@#$USAGE_REPORTING_AUTH_CLIENT_ID_TESTING#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_AUTH_CLIENT_SECRET_TESTING@@#$USAGE_REPORTING_AUTH_CLIENT_SECRET_TESTING#g" zappa_settings.json
    - sed -i "s#@@LOGGING_LEVEL@@#$LOGGING_LEVEL_TESTING#g" zappa_settings.json
    - pipenv run zappa deploy testing || pipenv run zappa update testing
    # ensure tables are created:
    - export AWS_ACCESS_KEY_ID="$TESTING_AWS_ACCESS_KEY_ID"
    - export AWS_SECRET_ACCESS_KEY="$TESTING_AWS_SECRET_ACCESS_KEY"
    - pipenv run bash -c "DEPLOYMENT_TYPE=testing python dynamodb/dynamodb.py"


deploy-testing-rest-lambda-docker:
  stage: deploy
  when: manual
  only:
    variables:
      - $CI_COMMIT_TAG =~ /^v[0-9]+[.][0-9]+[.][0-9]+[-]rc.[0-9]+$/
  # image: python:3.9.13
  before_script:
    - apk add --update python3 python3-dev py3-pip
    - python --version
    - pip --version
    # configure aws access credentials:
    - mkdir -p ~/.aws
    - echo -e "[default]\nregion=eu-central-1" > ~/.aws/config
    - echo -e "[default]\naws_access_key_id=$TESTINGZAPPA_AWS_ACCESS_KEY_ID\naws_secret_access_key=$TESTINGZAPPA_AWS_SECRET_ACCESS_KEY" > ~/.aws/credentials
    - pip install pipenv==2021.5.29
  script:
    - ls
    - chmod +x download-process-definitions.sh
    - ./download-process-definitions.sh
    - cd rest/
    - pipenv install --dev
    # create zappa_settings.json on-the-fly:
    - cp zappa_settings.json.template zappa_settings.json
    - sed -i "s/@@AWS_ACCESS_KEY_ID@@/$TESTINGDATA_AWS_ACCESS_KEY_ID/g" zappa_settings.json
    - sed -i "s#@@AWS_SECRET_ACCESS_KEY@@#$TESTINGDATA_AWS_SECRET_ACCESS_KEY#g" zappa_settings.json
    - sed -i "s/@@TESTING_SH_CLIENT_ID@@/$TESTING_SH_CLIENT_ID/g" zappa_settings.json
    - sed -i "s/@@TESTING_SH_CLIENT_SECRET@@/$TESTING_SH_CLIENT_SECRET/g" zappa_settings.json
    - sed -i "s/@@BACKEND_VERSION@@/$CI_COMMIT_TAG/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_NAME_MAIN@@/$RESULTS_S3_BUCKET_NAME_MAIN/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_NAME_CREODIAS@@/$RESULTS_S3_BUCKET_NAME_CREODIAS/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_NAME_USWEST@@/$RESULTS_S3_BUCKET_NAME_USWEST/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_ACCESS_KEY_ID_MAIN@@/$RESULTS_S3_BUCKET_ACCESS_KEY_ID_MAIN/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_ACCESS_KEY_ID_CREODIAS@@/$RESULTS_S3_BUCKET_ACCESS_KEY_ID_CREODIAS/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_ACCESS_KEY_ID_USWEST@@/$RESULTS_S3_BUCKET_ACCESS_KEY_ID_USWEST/g" zappa_settings.json
    - sed -i "s#@@RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_MAIN@@#$RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_MAIN#g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_CREODIAS@@/$RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_CREODIAS/g" zappa_settings.json
    - sed -i "s#@@RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_USWEST@@#$RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_USWEST#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_BASE_URL_TESTING@@#$USAGE_REPORTING_BASE_URL_TESTING#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_AUTH_URL_TESTING@@#$USAGE_REPORTING_AUTH_URL_TESTING#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_AUTH_CLIENT_ID_TESTING@@#$USAGE_REPORTING_AUTH_CLIENT_ID_TESTING#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_AUTH_CLIENT_SECRET_TESTING@@#$USAGE_REPORTING_AUTH_CLIENT_SECRET_TESTING#g" zappa_settings.json
    - sed -i "s#@@LOGGING_LEVEL@@#$LOGGING_LEVEL_TESTING#g" zappa_settings.json
    # generate zappa_settings.py for docker image
    - pipenv run zappa save-python-settings-file testing-docker
    # build docker image
    - docker build -t openeo-sh-zappa:latest .
    # login for AWS ECR docker
    - aws ecr get-login-password --region eu-central-1 | docker login --username AWS --password-stdin 127163565383.dkr.ecr.eu-central-1.amazonaws.com
    # re-tag the built image 
    - docker tag openeo-sh-zappa:latest 127163565383.dkr.ecr.eu-central-1.amazonaws.com/openeo-sh-zappa:latest
    # push docker image to AWS ECR
    - docker push 127163565383.dkr.ecr.eu-central-1.amazonaws.com/openeo-sh-zappa:latest
    # deploy lambda with new docker image
    - pipenv run zappa deploy testing-docker -d 127163565383.dkr.ecr.eu-central-1.amazonaws.com/openeo-sh-zappa:latest || pipenv run zappa update testing-docker -d 127163565383.dkr.ecr.eu-central-1.amazonaws.com/openeo-sh-zappa:latest
    # ensure tables are created:
    - export AWS_ACCESS_KEY_ID="$TESTING_AWS_ACCESS_KEY_ID"
    - export AWS_SECRET_ACCESS_KEY="$TESTING_AWS_SECRET_ACCESS_KEY"
    - pipenv run bash -c "DEPLOYMENT_TYPE=testing python dynamodb/dynamodb.py"


    # needs to be run only once!!!
    # - pipenv run aws ecr create-repository --repository-name openeo-zappa-docker --image-scanning-configuration scanOnPush=true --region region



deploy-production-rest-lambda:
  stage: deploy
  when: manual
  only:
    variables:
      - $CI_COMMIT_TAG =~ /^v[0-9]+[.][0-9]+[.][0-9]$/
  image: python:3.9.13
  before_script:
    # configure aws access credentials:
    - mkdir -p ~/.aws
    - echo -e "[default]\nregion=eu-central-1" > ~/.aws/config
    - echo -e "[default]\naws_access_key_id=$PRODZAPPA_AWS_ACCESS_KEY_ID\naws_secret_access_key=$PRODZAPPA_AWS_SECRET_ACCESS_KEY" > ~/.aws/credentials
    - pip install pipenv==2021.5.29
  script:
    - chmod +x download-process-definitions.sh
    - ./download-process-definitions.sh
    - cd rest/
    - pipenv install --dev
    # create zappa_settings.json on-the-fly:
    - cp zappa_settings.json.template zappa_settings.json
    - sed -i "s/@@AWS_ACCESS_KEY_ID@@/$PRODDATA_AWS_ACCESS_KEY_ID/g" zappa_settings.json
    - sed -i "s#@@AWS_SECRET_ACCESS_KEY@@#$PRODDATA_AWS_SECRET_ACCESS_KEY#g" zappa_settings.json
    - sed -i "s/@@PRODUCTION_SH_CLIENT_ID@@/$PRODUCTION_SH_CLIENT_ID/g" zappa_settings.json
    - sed -i "s/@@PRODUCTION_SH_CLIENT_SECRET@@/$PRODUCTION_SH_CLIENT_SECRET/g" zappa_settings.json
    - sed -i "s/@@BACKEND_VERSION@@/$CI_COMMIT_TAG/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_NAME_MAIN@@/$RESULTS_S3_BUCKET_NAME_MAIN_PRODUCTION/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_NAME_CREODIAS@@/$RESULTS_S3_BUCKET_NAME_CREODIAS_PRODUCTION/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_NAME_USWEST@@/$RESULTS_S3_BUCKET_NAME_USWEST_PRODUCTION/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_ACCESS_KEY_ID_MAIN@@/$RESULTS_S3_BUCKET_ACCESS_KEY_ID_MAIN_PRODUCTION/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_ACCESS_KEY_ID_CREODIAS@@/$RESULTS_S3_BUCKET_ACCESS_KEY_ID_CREODIAS_PRODUCTION/g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_ACCESS_KEY_ID_USWEST@@/$RESULTS_S3_BUCKET_ACCESS_KEY_ID_USWEST_PRODUCTION/g" zappa_settings.json
    - sed -i "s#@@RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_MAIN@@#$RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_MAIN_PRODUCTION#g" zappa_settings.json
    - sed -i "s/@@RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_CREODIAS@@/$RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_CREODIAS_PRODUCTION/g" zappa_settings.json
    - sed -i "s#@@RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_USWEST@@#$RESULTS_S3_BUCKET_SECRET_ACCESS_KEY_USWEST_PRODUCTION#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_BASE_URL_PRODUCTION@@#$USAGE_REPORTING_BASE_URL_PRODUCTION#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_AUTH_URL_PRODUCTION@@#$USAGE_REPORTING_AUTH_URL_PRODUCTION#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_AUTH_CLIENT_ID_PRODUCTION@@#$USAGE_REPORTING_AUTH_CLIENT_ID_PRODUCTION#g" zappa_settings.json
    - sed -i "s#@@USAGE_REPORTING_AUTH_CLIENT_SECRET_PRODUCTION@@#$USAGE_REPORTING_AUTH_CLIENT_SECRET_PRODUCTION#g" zappa_settings.json
    - sed -i "s#@@LOGGING_LEVEL@@#$LOGGING_LEVEL_PRODUCTION#g" zappa_settings.json
    - pipenv run zappa deploy production || pipenv run zappa update production
    # ensure tables are created:
    - export AWS_ACCESS_KEY_ID="$PRODDATA_AWS_ACCESS_KEY_ID"
    - export AWS_SECRET_ACCESS_KEY="$PRODDATA_AWS_SECRET_ACCESS_KEY"
    - pipenv run bash -c "DEPLOYMENT_TYPE=production python dynamodb/dynamodb.py"
