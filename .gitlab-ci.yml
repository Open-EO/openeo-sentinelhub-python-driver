image:
  name: docker/compose:1.24.1
  entrypoint: ["/bin/sh","-l","-c"]

services:
  - docker:dind

stages:
  - test
  - deploy

linting:
  stage: test
  image: python:3.6.8
  script:
    - pip install --upgrade black==20.8b1
    # make sure that the *same* version is used in Pipfiles to avoid incompatibilities:
    - grep 'black = "==20.8b1"' workers/Pipfile
    - grep 'black = "==20.8b1"' rest/Pipfile
    # check the files for correct formatting:
    - black -l 120 --check . || exit 1

integration tests:
  stage: test
  script:
    - '[ "`df -m / | tail -n -1 | awk ''{ print $4}''`" -ge "10" ] || (echo "NO DISK SPACE LEFT" && exit 1)'
    - docker-compose -f docker-compose.yml -f docker-compose.pytest.yml build
    - docker-compose -f docker-compose.yml -f docker-compose.pytest.yml up --exit-code-from pytest
  after_script:
    - docker-compose -f docker-compose.yml -f docker-compose.pytest.yml down -v

unit tests:
  stage: test
  script:
    - cd workers/tests/
    - set | grep SENTINEL | tr -d "'" >> .env
    - docker-compose build
    - docker-compose up --exit-code-from workers-unittests
  after_script:
    - docker-compose down -v


## GITHUB:
publish_github:
  stage: deploy
  when: manual
  only:
    - master
  before_script:
    - apk add --no-cache git openssh-client
  script:
    # prepare SSH credentials for cloning from GitHub:
    - mkdir -m 700 ~/.ssh
    - echo ${GITHUB_SSH_PRIVATE_KEY_BASE64} | base64 -d > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - echo ${GITHUB_SSH_KNOWN_HOST} > ~/.ssh/known_hosts
    # remove remote for github repo if it exists:
    - if git remote | grep github > /dev/null; then git remote rm github; fi
    # add remote for github repo:
    - git remote add github git@github.com:Open-EO/openeo-sentinelhub-python-driver.git
    - git config --global user.email "info@sinergise.com"
    - git config --global user.name "sentinel-hub"
    - git push github master
    - git push --tags github master
  after_script:
    # clean the git remotes even if job fails
    # remove remote for github if it exists
    - if git remote | grep github > /dev/null; then git remote rm github; fi


deploy-testing-rest-lambda:
  stage: deploy
  when: manual
  only:
    variables:
      - $CI_COMMIT_TAG =~ /^v[0-9]+[.][0-9]+[.][0-9]+[-]rc.[0-9]+$/
  image: python:3.6.8
  before_script:
    # configure aws access credentials:
    - mkdir -p ~/.aws
    - echo -e "[default]\nregion=eu-central-1" > ~/.aws/config
    - echo -e "[default]\naws_access_key_id=$TESTINGZAPPA_AWS_ACCESS_KEY_ID\naws_secret_access_key=$TESTINGZAPPA_AWS_SECRET_ACCESS_KEY" > ~/.aws/credentials
    - pip install --upgrade pipenv
  script:
    - chmod +x download-process-definitions.sh
    - ./download-process-definitions.sh
    - cd rest/
    - pipenv install --dev
    # create zappa_settings.json on-the-fly:
    - cp zappa_settings.json.template zappa_settings.json
    - sed -i "s/@@AWS_ACCESS_KEY_ID@@/$TESTINGDATA_AWS_ACCESS_KEY_ID/g" zappa_settings.json
    - sed -i "s#@@AWS_SECRET_ACCESS_KEY@@#$TESTINGDATA_AWS_SECRET_ACCESS_KEY#g" zappa_settings.json
    - sed -i "s/@@S3_DATA_BUCKET@@/$TESTING_S3_BUCKET/g" zappa_settings.json
    - sed -i "s/@@TESTING_SH_CLIENT_ID@@/$TESTING_SH_CLIENT_ID/g" zappa_settings.json
    - sed -i "s/@@TESTING_SH_CLIENT_SECRET@@/$TESTING_SH_CLIENT_SECRET/g" zappa_settings.json
    - sed -i "s/@@BACKEND_VERSION@@/$CI_COMMIT_TAG/g" zappa_settings.json
    - pipenv run zappa deploy testing || pipenv run zappa update testing
    # ensure tables are created:
    - export AWS_ACCESS_KEY_ID="$TESTING_AWS_ACCESS_KEY_ID"
    - export AWS_SECRET_ACCESS_KEY="$TESTING_AWS_SECRET_ACCESS_KEY"
    - pipenv run bash -c "DEPLOYMENT_TYPE=testing python dynamodb.py"


deploy-production-rest-lambda:
  stage: deploy
  when: manual
  only:
    variables:
      - $CI_COMMIT_TAG =~ /^v[0-9]+[.][0-9]+[.][0-9]$/
  image: python:3.6.8
  before_script:
    # configure aws access credentials:
    - mkdir -p ~/.aws
    - echo -e "[default]\nregion=eu-central-1" > ~/.aws/config
    - echo -e "[default]\naws_access_key_id=$PRODZAPPA_AWS_ACCESS_KEY_ID\naws_secret_access_key=$PRODZAPPA_AWS_SECRET_ACCESS_KEY" > ~/.aws/credentials
    - pip install --upgrade pipenv
  script:
    - chmod +x download-process-definitions.sh
    - ./download-process-definitions.sh
    - cd rest/
    - pipenv install --dev
    # create zappa_settings.json on-the-fly:
    - cp zappa_settings.json.template zappa_settings.json
    - sed -i "s/@@AWS_ACCESS_KEY_ID@@/$PRODDATA_AWS_ACCESS_KEY_ID/g" zappa_settings.json
    - sed -i "s#@@AWS_SECRET_ACCESS_KEY@@#$PRODDATA_AWS_SECRET_ACCESS_KEY#g" zappa_settings.json
    - sed -i "s/@@S3_DATA_BUCKET@@/$PRODDATA_S3_BUCKET/g" zappa_settings.json
    - sed -i "s/@@PRODUCTION_SH_CLIENT_ID@@/$PRODUCTION_SH_CLIENT_ID/g" zappa_settings.json
    - sed -i "s/@@PRODUCTION_SH_CLIENT_SECRET@@/$PRODUCTION_SH_CLIENT_SECRET/g" zappa_settings.json
    - sed -i "s/@@BACKEND_VERSION@@/$CI_COMMIT_TAG/g" zappa_settings.json
    - pipenv run zappa deploy production || pipenv run zappa update production
    # ensure tables are created:
    - export AWS_ACCESS_KEY_ID="$PRODDATA_AWS_ACCESS_KEY_ID"
    - export AWS_SECRET_ACCESS_KEY="$PRODDATA_AWS_SECRET_ACCESS_KEY"
    - pipenv run bash -c "DEPLOYMENT_TYPE=production python dynamodb.py"
